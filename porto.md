## ë³€ìˆ˜ë“¤ì— ëŒ€í•œ ë©”íƒ€ë°ì´í„° ì •ë¦¬

forë¬¸ ì‚¬ìš©í•´ ë³€ìˆ˜ì˜ ì—­í• /ë°ì´í„° ìœ í˜•/ë³´ì¡´ ì—¬ë¶€/dtype/ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ë¥˜í•œ metadata ìƒì„±

<br/>

```py
data = [] #ì—¬ê¸°ì— ê° ë³€ìˆ˜ì˜ ë©”íƒ€ì •ë³´ë¥¼ ë‹´ì„ ë”•ì…”ë„ˆë¦¬ í•˜ë‚˜ì”© ì¶”ê°€

#  ë³€ìˆ˜ ì—­í•  êµ¬ë¶„
if feature == 'target':
    use = 'target'
elif feature == 'id':
    use = 'id'
else:
    use = 'input'


# ë³€ìˆ˜ ë°ì´í„° ìœ í˜•
if 'bin' in feature or feature == 'target':
    type = 'binary'  # 0/1 ê°™ì€ ì´ì§„ê°’
elif 'cat' in feature or feature == 'id':
    type = 'categorical'  # ë²”ì£¼í˜• ë³€ìˆ˜
elif trainset[feature].dtype == float or isinstance(trainset[feature].dtype, float):
    type = 'real'  # ì‹¤ìˆ˜í˜•
elif trainset[feature].dtype == int:
    type = 'integer'  # ì •ìˆ˜í˜•

# ë³´ì¡´ ì—¬ë¶€ (preserve)
preserve = True
if feature == 'id':
    preserve = False # ë¶„ì„ì— í•„ìš”í•œ ë³€ìˆ˜ë§Œ ë³´ì¡´í• ê±´ë° idëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë¶„ì„ì— ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ false

# dtype
dtype = trainset[feature].dtype #íŒë‹¤ìŠ¤ì˜ ì›ë˜ ë°ì´í„° íƒ€ì… ì‚¬ìš©

# category
if 'ind' in feature:
    category = 'individual' #ì‚¬ëŒ
elif 'reg' in feature:
    category = 'registration' #ë“±ë¡ ì •ë³´
elif 'car' in feature:
    category = 'car' #ìë™ì°¨ ê´€ë ¨
elif 'calc' in feature:
    category = 'calculated' #ê³„ì‚°ëœ ê°’

# metadata ìƒì„±
feature_dictionary = {
    'varname': feature,
    'use': use,
    'type': type,
    'preserve': preserve,
    'dtype': dtype,
    'category' : category
}
data.append(feature_dictionary) # ëª¨ë“  ë³€ìˆ˜ë¥¼ í•˜ë‚˜ì”© ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¤ì–´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

metadata = pd.DataFrame(data, columns=['varname', 'use', 'type', 'preserve', 'dtype', 'category']) #íŒë‹¤ìŠ¤ DataFrameìœ¼ë¡œ ë§Œë“¤ê³ 
metadata.set_index('varname', inplace=True) #varnameì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
```
- varnameì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•œë‹¤ëŠ” ê²ƒì€<br/>
![prac8](./image/prac8.png)<br/>
ì´ë ‡ê²Œ íŒë‹¤ìŠ¤ì—ì„œëŠ” ìë™ìœ¼ë¡œ í–‰ì˜ ë²ˆí˜¸ë¥¼ 0, 1, 2...ë¡œ ë¶™ì´ëŠ”ë° <br/>
![prac9](./image/prac9.png)<br/>
ì¸ë±ìŠ¤ë¥¼ varnameìœ¼ë¡œ ì„¤ì •í•˜ë©´ varname ì—´(id, target, feature1 ë“±..)ì´ 0, 1, 2 ëŒ€ì‹  í–‰ì˜ ë²ˆí˜¸ë¡œ ì“°ì´ëŠ” ê²ƒ!<br/>
ë‹¤ì‹œ ë§í•´, í–‰ì˜ ì´ë¦„(label)ì´ 'id', 'target', 'feature1' ë“±ì´ ëœë‹¤.

<br/>
<br/>

```py
metadata[(metadata.type == 'categorical') & (metadata.preserve)].index
# type == 'categorical' : ë²”ì£¼í˜• ë³€ìˆ˜ë§Œ ì„ íƒ
# preserve == : True ë¶„ì„ì— ì‚¬ìš©í•  ë³€ìˆ˜ë§Œ ì„ íƒ
# .index : í•´ë‹¹ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë³€ìˆ˜ ì´ë¦„ë§Œ ì¶”ì¶œ
```

- ì´ë ‡ê²Œ í•˜ë©´ ë‚˜ì¤‘ì— ì›í•˜ëŠ” ë³€ìˆ˜ë§Œ ì‰½ê²Œ ì„ íƒ/í•„í„°ë§í•  ìˆ˜ ìˆìŒ <br/>
ğŸ’¡ ì´ë ‡ê²Œ metadata í”„ë ˆì„ì„ ë§Œë“¤ì–´ë‘ë©´ ì…€í”„ ìë™í™” ë„êµ¬ë¥¼ ë§Œë“œëŠ” ì…ˆ! ë‹¤ë¥¸ ë°ì´í„°ì…‹ì—ì„œë„ ìœ ìš©í•˜ë‹¤ <br/>
íŠ¹íˆ *ë³€ìˆ˜ê°€ 30ê°œ ì´ìƒì¼ ë•Œ*, *ì—¬ëŸ¬ ë°ì´í„°ì…‹ì— ê³µí†µì ìœ¼ë¡œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì§œì•¼í•  ë•Œ*, *EDA, ëª¨ë¸ ì‹¤í—˜ì„ ë°˜ë³µì ìœ¼ë¡œ í•  ë•Œ* ìœ ìš©í•¨
<br/>
<br/>
<br/>

## íŠ¹ì • ë³€ìˆ˜ë§Œ ê³±í•˜ê±°ë‚˜ ì œê³±í•´ì„œ ë³€í™˜í•˜ê¸°
 ì‹¤ìˆ˜(float).describe ê²°ê³¼ ë³´ê³  
 
 ```py
 (pow(trainset['ps_car_12']*10,2)).head(10)

 (pow(trainset['ps_car_15'],2)).head(10)
 ```

 - 'ps_car_12'ëŠ” 10ì„ ê³±í•œ í›„ ì œê³±, 'ps_car_15'ëŠ” ì œê³±í•¨. ì´ìœ ëŠ”?ğŸ¤”
    - ps_car_12: ìì—°ìˆ˜ ì œê³±ê·¼ì„ 10ìœ¼ë¡œ ë‚˜ëˆˆ ê°’
        - ì‹¤ì œ ìì—°ìˆ˜í˜• ë°ì´í„°ë¥¼ âˆš ì—°ì‚° + 10ìœ¼ë¡œ ë‚˜ëˆˆ ê²ƒ.
        - ì˜ˆ: ì°¨ëŸ‰ ë§ˆë ¥ ìˆ˜, ë¬´ê²Œ, ì—°ì‹ ë“± ì‹¤ìˆ˜í˜•ì¸ë° ë„ˆë¬´ í° ê°’ì„ ì¤„ì´ê¸° ìœ„í•´ ë³€í˜•í–ˆì„ ê°€ëŠ¥ì„±
    > ps_car_12ëŠ” âˆšê°’ì´ë‹ˆê¹Œ â†’ ì œê³±í•˜ë©´ ì›ë˜ ìì—°ìˆ˜ ê°’ ë³µì›<br/> âˆš4 / 10 = 0.2 â†’ ì œê³±í•˜ë©´ 0.04.<br/>
    ê·¸ëŸ¬ë‹ˆê¹Œ ì œê³±í•˜ê³  10ì„ ê³±í•˜ë©´ ì›ë˜ê°’ì„ ê°„ì ‘ì ìœ¼ë¡œ ë³µì› ê°€ëŠ¥

    <br/>

  - ps_car_15: 
    - ì´ê±´ ì •ìˆ˜ë¥¼ ë‹¨ìˆœíˆ âˆš ì—°ì‚°ë§Œ í•œ ê°’ì´ë¼ ì¹´í…Œê³ ë¦¬ì ì¸ ìˆ«ì íŠ¹ì„±ì´ ìˆê±°ë‚˜,
    - ì•„ë‹ˆë©´ ì–´ë–¤ ìˆœì„œí˜• íŠ¹ì„±ì— ë£¨íŠ¸ë§Œ ì”Œìš´ ì¼€ì´ìŠ¤ì¼ ìˆ˜ë„ ìˆìŒ
    > âˆš ìì—°ìˆ˜ë‹ˆê¹Œ â†’ ì œê³±í•˜ë©´ ì •ìˆ˜ë¡œ ë³µì›ë¨!
<br/>
<br/>

 ğŸ’¡ ps_car_12, ps_car_15ëŠ” ì›ë˜ ìì—°ìˆ˜ ê°’ì—ì„œ âˆš ì—°ì‚°ì„ ê±°ì³ ë³€í˜•ëœ ê²ƒì´ê³ , ë¶„ì„ìëŠ” **ì´ê±¸ ì œê³±í•¨ìœ¼ë¡œì¨ ì›ë˜ ì˜ë¯¸ ìˆëŠ” ì •ìˆ˜ë¡œ ë³µì›í•˜ë ¤ í•œ ê²ƒ**


â¡ï¸ ì´ì™¸ì— *10ìœ¼ë¡œ ìŠ¤ì¼€ì¼ í‚¤ìš°ê³ , ì œê³±ìœ¼ë¡œ ë¹„ì„ í˜• ë³€í™˜(ex. ì‘ì€ ì°¨ì´ê°€ ë” í° ì˜í–¥ì„ ë¯¸ì¹˜ê²Œ)ê¹Œì§€ í•´ì„œ ë³€ìˆ˜ ì˜í–¥ë ¥ ê°•ì¡°í•˜ê¸°ë„ í•¨!

<br/>
<br/>
<br/>


# ë²”ì£¼í˜• ë³€ìˆ˜ target encoding

## ê°œë… ì„¤ëª…
### target encdoingì´ë€?
- ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ìˆ«ìë¡œ ë°”ê¾¸ëŠ” ê¸°ë²• ì¤‘ í•˜ë‚˜
    - ê° ë²”ì£¼ì— ëŒ€í•´ ê·¸ ë²”ì£¼ì˜ í‰ê·  íƒ€ê²Ÿê°’ìœ¼ë¡œ ìˆ«ìë¥¼ ë¶€ì—¬ <br/>
    ![prac11](./image/prac11.png) <br/>
    - ì´ë ‡ê²Œ ì§€ì—­ì´ë¼ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ìˆ«ìë¡œ ë°”ê¿”ì„œ ëª¨ë¸ì— ë„£ìŒ

<br/>

### smoothing ê¸°ë²•
```py
def target_encode(trn_series=None,
                  tst_series=None,
                  target=None,
                  min_samples_leaf=1,
                  smoothing=1, 
                  noise_level=0):
```
![prac10](./image/prac10.png)
- ë‹¨ìˆœ í‰ê·  ëŒ€ì‹ , ë¹ˆë„ìˆ˜ì™€ ì „ì²´ í‰ê· ì„ í•¨ê»˜ ê³ ë ¤í•˜ëŠ” ê¸°ë²•
- ê³¼ì í•©ì„ ë°©ì§€í•  ìˆ˜ ìˆìŒ
<br/>

## íë¦„ ì •ë¦¬
### [1] add_noise() : ì´ˆê¸° ë…¸ì´ì¦ˆ ë”í•˜ê¸°
```py
def add_noise(series, noise_level):
    return series * (1 + noise_level * np.random.randn(len(series)))
```
- ì¸ì½”ë”©ëœ ê°’ì— ì•½ê°„ì˜ ë…¸ì´ì¦ˆë¥¼ ë”í•´ì„œ ëª¨ë¸ì´ ê³¼ë„í•˜ê²Œ í•´ë‹¹ í”¼ì³ì— ì˜ì¡´í•˜ì§€ ì•Šë„ë¡ ë°©ì§€
    - noise_levelì´ í´ìˆ˜ë¡ ë” ë§ì€ ëœë¤ê°’ ì¶”ê°€
<br/>


### [2] assert : ì´ˆê¸° ì•ˆì „ ê²€ì‚¬ ë° ë°ì´í„° ì¤€ë¹„
```py
    assert len(trn_series) == len(target)
    assert trn_series.name == tst_series.name
```
1. trn_series(í•™ìŠµìš© ë²”ì£¼í˜• ë³€ìˆ˜)ì™€ targetê°’ *ê¸¸ì´ê°€ ê°™ì€ì§€* í™•ì¸, ì•ˆ ë§ìœ¼ë©´ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œì¼œ í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ë‹¨
    - ì—´ë§ˆë‹¤ ì •í™•íˆ ëŒ€ì‘ë˜ëŠ” ê°’ì´ ìˆì–´ì•¼ í‰ê·  ê³„ì‚° ê°€ëŠ¥
    - ë‘˜ì˜ ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ê° ë²”ì£¼í˜• ê°’ì´ ì–´ë–¤ íƒ€ê²Ÿê°’ê³¼ ì—°ê²°ë˜ì–´ì•¼ í•˜ëŠ”ì§€ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ê³„ì‚° ìì²´ê°€ ë¬´ì˜ë¯¸í•´ì§

2. trainìš©ê³¼ testìš© ë²”ì£¼í˜• ë³€ìˆ˜ì˜ *ì—´ ì´ë¦„ì´ ê°™ì€ì§€* í™•ì¸
    - trainìš©ìœ¼ë¡œ ê³„ì‚°í•œ í‰ê· ê°’ì„ test ë°ì´í„°ì—ë„ ì ìš©í•˜ë ¤ê³  í•  ë•Œ, ì—´ ì´ë¦„ì´ ê°™ì•„ì•¼ merge ê°€ëŠ¥ <br/>
    ```py
    pd.merge(tst_series, í‰ê· ê°’_í…Œì´ë¸”, on='Gender')
    ```

3. trn_seriesì™€ targetì„ ì˜†ìœ¼ë¡œ í•©ì³ì„œ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ë§Œë“¬ -> ê·¸ë£¹ë³„ í‰ê·  ê³„ì‚°ì„ ì‰½ê²Œ í•˜ê¸° ìœ„í•´
<br/>


### [3] train ê¸°ì¤€ìœ¼ë¡œ ê° ë²”ì£¼ì˜ íƒ€ê²Ÿ í‰ê·  ê³„ì‚°
```py

    temp = pd.concat([trn_series, target], axis=1)
    # Compute target mean 
    averages = temp.groupby(by=trn_series.name)[target.name].agg(["mean", "count"])
```
<br/>


### [4] smoothing ê³„ì‚°
```py
    # Compute smoothing
    # sigmoid í•¨ìˆ˜ ì‚¬ìš© (countê°€ ì»¤ì§€ë©´ ê°’ì´ 1ì—, countê°€ ì‘ìœ¼ë©´ 0ì— ê°€ê¹Œì›Œì§€ë„ë¡)
    smoothing = 1 / (1 + np.exp(-(averages["count"] - min_samples_leaf) / smoothing))
```
<br/>


### [5] ìµœì¢… ì¸ì½”ë”© ê°’ ê³„ì‚°
```py
    # Apply average function to all target data
    # ì‚¬ì „ í‰ê· (prior) = ë²”ì£¼ ìƒ˜í”Œì´ ë¶€ì¡±í•´ ë²”ì£¼ ì •ë³´ê°€ ë¶€ì¡±í•  ë•Œ ê¸°ì¤€ì´ ë  ìˆ˜ ìˆëŠ” "ê¸°ë³¸ê°’"
    prior = target.mean()

    # The bigger the count the less full_avg is taken into account
    # ìµœì¢… ì¸ì½”ë”© ê°’ ê³„ì‚°
    averages[target.name] = prior * (1 - smoothing) + averages["mean"] * smoothing #ì¸ì½”ë”© ê°’ì„ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ê³„ì‚°
    averages.drop(["mean", "count"], axis=1, inplace=True) #mean, count ì„ì‹œ ê³„ì‚°í•´ì„œ smoothing ê³„ì‚°ì— ì¼ìœ¼ë‹ˆ ë¶ˆí•„ìš”í•œ ì—´ì€ ì‚­ì œ
```
<br/>

```py
í‰ê· ê°’ = prior * (1 - smoothing) + ë²”ì£¼ë³„ í‰ê·  * smoothing
```
<br/>

- ê° ë²”ì£¼ì˜ í‰ê· ì„ ì“°ë©´ ìƒ˜í”Œ ìˆ˜ê°€ ì ì€ ë²”ì£¼ì¼ìˆ˜ë¡ ë…¸ì´ì¦ˆì— íœ˜ë‘˜ë¦¬ë¯€ë¡œ ìœ„ì²˜ëŸ¼ *ì‚¬ì „ í‰ê· (prior)*ê³¼ *ë²”ì£¼ í‰ê· (mean)*ì„ ì ì ˆíˆ ì„ëŠ” ë°©ì‹ì„ ì‚¬ìš©
    - ğŸ’¡ ë²”ì£¼ì— ëŒ€í•œ ë°ì´í„°ê°€ ì ì„ìˆ˜ë¡ priorìª½ì„ ë¯¿ê³ ,
    -    ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ ë²”ì£¼ ìì²´ì˜ í‰ê· ì„ ë” ë¯¿ê²Œ ë§Œë“œëŠ” ê²ƒ!

<br/>

### [6] pd.merge() : train/test ë°ì´í„°ì— ì¸ì½”ë”© ê°’ ë§¤í•‘
### [7] ì¸ë±ìŠ¤ ë³µì›
```py
# Apply averages to trn and tst series
    ft_trn_series = pd.merge( #ìœ„ì—ì„œ ê³„ì‚°í•œ í‰ê· ê°’ì„ train/test ë°ì´í„°ì— ë³‘í•©í•´ì„œ ì¸ì½”ë”©ëœ ê°’ ìƒì„±
        trn_series.to_frame(trn_series.name),
        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),
        on=trn_series.name,
        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)
```

```py
    # pd.merge does not keep the index so restore it
    ft_trn_series.index = trn_series.index 
    ft_tst_series = pd.merge(
        tst_series.to_frame(tst_series.name),
        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),
        on=tst_series.name,
        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)

    # pd.merge does not keep the index so restore it
    ft_tst_series.index = tst_series.index
```

1. ê° ë²”ì£¼ì— ëŒ€í•´ ê³„ì‚°í•œ averagesë¥¼ ì›ë˜ ë°ì´í„°(trn_series, tst_series)ì— ë§¤í•‘í•´ì•¼ í•˜ë¯€ë¡œ **pd.merge()**ë¥¼ ì‚¬ìš©í•´ì„œ ë²”ì£¼ â†’ ì¸ì½”ë”©ê°’ ë¶™ì´ëŠ” ì‘ì—… ì‹¤í–‰

2. BUT mergeëŠ” SQL ê¸°ë°˜ joinì´ë¯€ë¡œ pandas ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•©ì¹˜ì§€ ì•Šê³ , ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ í•©ì¹œë‹¤!
    - ê·¸ë˜ì„œ pd.merge()ë¥¼ í•˜ë©´ ì›ë˜ ì¸ë±ìŠ¤ê°€ ì‚¬ë¼ì§ 
    - ì´ê±¸ ë³µì›í•˜ê¸° ìœ„í•´ 
    ```ft_tst_series.index = tst_series.index``` ê°™ì€ ì½”ë“œë¥¼ ì‘ì„±
<br/>


### [8] ë§ˆì§€ë§‰ add_noise()
```py
    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)
```

- íƒ€ê²Ÿ ëˆ„ìˆ˜ë€?
    - í•™ìŠµ ê³¼ì •ì—ì„œ í…ŒìŠ¤íŠ¸ì— ëŒ€í•œ ì •ë³´ê°€ (ì§ê°„ì ‘ì ìœ¼ë¡œ) í¬í•¨ë˜ì–´ ëª¨ë¸ ì„±ëŠ¥ì´ ê³¼ë„í•˜ê²Œ ì¢‹ì•„ì§€ëŠ” í˜„ìƒ<br/>
    ```py
    temp = pd.concat([trn_series, target], axis=1)
    averages = temp.groupby('category')['target'].mean()
    ```
    - targetì—ì„œ í•™ìŠµ ë°ì´í„°ë¡œ ê³„ì‚°í•œ í‰ê· ê°’ ìì²´ë§Œ! ê°€ì ¸ì˜¤ê¸°ë§Œ í•´ì•¼ë¨ (avergesì— ì €ì¥)
    <br/>

    ```py
    df_all = pd.concat([train, test])
    df_all['category_encoded'] = df_all.groupby('category')['target'].transform('mean')
    ```
    - ê·¸ëŸ°ë° ë§Œì•½ ìœ„ ê°™ì€ ì½”ë“œë¡œ testì˜ íƒ€ê²Ÿ ê°’ê¹Œì§€ í¬í•¨í•´ì„œ ê³„ì‚°í•œ í‰ê· ì„ ë°”ë¡œ dfì— ë¶™ì´ë©´ ë‹µì•ˆì§€ë¥¼ ë³¸ ê²ƒì´ë‚˜ ë‹¤ë¦„ ì—†ìŒ

    - ëˆ„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ, ë…¸ì´ì¦ˆ ì²˜ë¦¬ í•„ìš”
      - íƒ€ê²Ÿ ì¸ì½”ë”©ì€ target ê¸°ë°˜ ê°’ì´ë¯€ë¡œ ë„ˆë¬´ ì§ì ‘ì ì¸ ì¸ì½”ë”©ì´ ë˜ë©´ ê³¼ì í•© ìœ„í—˜ì´ ìˆë‹¤..!
      - ê·¸ë˜ì„œ ì•½ê°„ì˜ ë…¸ì´ì¦ˆë¥¼ ì„ì–´ ì¸ìœ„ì ì¸ ë¶„ì‚°ì„ ì¶”ê°€, ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì¸ ìƒíƒœë¡œ ë§ˆë¬´ë¦¬!

    <br/>

    - í•´ê²°ë²•
    1. trn_seriesì™€ targetë§Œìœ¼ë¡œ í‰ê· ì„ ê³„ì‚°<br/>
        tst_seriesì—ëŠ” ì˜¤ì§ 'category' ê°’ë§Œ ì‚¬ìš©í•´ì„œ merge<br/>
        ë§ˆì§€ë§‰ì— ë…¸ì´ì¦ˆë¥¼ ì‚´ì§ ì¶”ê°€í•´ í‰ê· ê°’ ìì²´ì— ëª¨ë¸ì´ ì˜ì¡´í•˜ì§€ ì•Šë„ë¡ ì¼ë°˜í™”ì‹œí‚¤ê¸°
    2. KFold ë°©ì‹ìœ¼ë¡œ ê°™ì€ train ë‚´ì—ì„œë„ ëˆ„ìˆ˜ ë§‰ëŠ” ì¸ì½”ë”©

<br/>
<br/>

# Ensamble ëª¨ë¸
- ì—¬ëŸ¬ ê°œì˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê³ , ì´ ëª¨ë¸ë“¤ì˜ ì˜ˆì¸¡ê°’ì„ ë‹¤ì‹œ ìµœì¢… ëª¨ë¸(stacker)ë¡œ ë¬¶ì–´ì„œ ë” ì •í™•í•œ ì˜ˆì¸¡í•˜ê¸°

- ê·¸ ì¤‘ì—ì„œë„ í•´ë‹¹ ì½”ë“œì—ì„œëŠ” K-Fold Cross Validation(K-ê²¹ êµì°¨ ê²€ì¦)ê³¼ ìŠ¤íƒœí‚¹(stacking)ì„ ê²°í•©í•´ ì‚¬ìš©!

## K-Fold Cross Validation
- ë°ì´í„°ë¥¼ Kê°œì˜ ë¶€ë¶„(Fold)ë¡œ ë‚˜ëˆ”
- ê·¸ ì¤‘ í•˜ë‚˜ëŠ” ê²€ì¦ìš©, ë‚˜ë¨¸ì§€ëŠ” í•™ìŠµìš©ìœ¼ë¡œ ì‚¬ìš©
- ì´ ê³¼ì •ì„ Kë²ˆ ë°˜ë³µí•´ì„œ ëª¨ë“  ë°ì´í„°ê°€ í•œë²ˆì‹ ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš©ë˜ë„ë¡ í•¨
- ì´ ë°©ì‹ì€ ëª¨ë¸ì´ ë°ì´í„°ì— ê³¼ì í•©ë˜ì§€ ì•Šë„ë¡ í•´ì£¼ê³ , ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë” ì •í™•íˆ í‰ê°€í•  ìˆ˜ ìˆìŒ


## Stacker
- RandomForest, XGBoost, LogisticRegression ë“± ê°œë³„ ëª¨ë¸ë“¤ì„ ê°ê° ë…ë¦½ì ìœ¼ë¡œ í›ˆë ¨í•˜ì—¬ ì˜ˆì¸¡í•œ í›„, ê·¸ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ë°›ì•„ì„œ ìµœì¢… ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸
<br/>

â¡ï¸ ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§„ ì—¬ëŸ¬ ëª¨ë¸ë“¤ì˜ ì˜ˆì¸¡ì„ ì¡°í•©í•˜ê¸° ë•Œë¬¸ì— í•˜ë‚˜ì˜ ëª¨ë¸ë³´ë‹¤ ë” ì¢‹ì€ ì„±ëŠ¥ ê¸°ëŒ€ ê°€ëŠ¥!
- K-Foldë¡œ í•™ìŠµ -> ëª¨ë¸ ê³¼ì í•© ìš°ë ¤ low
- stacking -> ê°œë³„ ëª¨ë¸ë“¤ì˜ ì•½ì  ë³´ì™„ ê°€ëŠ¥

